{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd0b63a3",
   "metadata": {},
   "source": [
    "# Top Repositories for GitHubTopics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b33f05",
   "metadata": {},
   "source": [
    "## Pick a website and describe your objectives\n",
    "\n",
    "- Browse through different sites and pick on to scrape. Check the \"Project Ideas\" section for inspiration.\n",
    "- Identify the information you'd like to scrape from the site. Decide the format of the output CSV file.\n",
    "- Summarize your project idea and outline your strategy in a Juptyer notebook. Use the \"New\" button above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0fe667",
   "metadata": {},
   "source": [
    "#### Project Outline:\n",
    "- We're going to scrape https://github.com/topics\n",
    "- We'll get a list of topics. For each topic, we'll get topic title, topic page URL and topic description\n",
    "- For each topic, we'' get the top 25 repositories in the topic from the topic page\n",
    "- For each repository, we'll grab the repo name, username, stars and repo URL\n",
    "- For each topic we'll create a CSV file in the following format:\n",
    "```\n",
    "   Repo Name,Username,Stars,Repo URL\n",
    "   three.js,mrdoob,77200,https://github.com/mrdoob/three.js\n",
    "   libgdx,libgdx,19400,https://github.com/libgdx/libgdx\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde4e71f",
   "metadata": {},
   "source": [
    "## Use the requests library to download web pages\n",
    "(I'm using anaconda so there is no need for installing)\n",
    "\n",
    "- Inspect the website's HTML source and identify the right URLs to download.\n",
    "- Download and save web pages locally using the requests library.\n",
    "- Create a function to automate downloading for different topics/search queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a775cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdc55bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_url = 'https://github.com/topics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13c4bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(topics_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c40fd",
   "metadata": {},
   "source": [
    "- Here we use the requests library to create a response object hence downloading the webpage. \n",
    "- We can check if the request was successful or not by using 'response.status_code' which will return between 200-299 if it was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16ce89d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29565dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174310"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c07988",
   "metadata": {},
   "source": [
    "- We see the webpage downloaded is actually very huge in size and displaying it will only make it difficult to manage so rather we store this in a variable called page_contents and limit the output of a length 1000 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d028e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n<!DOCTYPE html>\\n<html lang=\"en\" data-color-mode=\"auto\" data-light-theme=\"light\" data-dark-theme=\"dark\">\\n  <head>\\n    <meta charset=\"utf-8\">\\n  <link rel=\"dns-prefetch\" href=\"https://github.githubassets.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://avatars.githubusercontent.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://github-cloud.s3.amazonaws.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://user-images.githubusercontent.com/\">\\n  <link rel=\"preconnect\" href=\"https://github.githubassets.com\" crossorigin>\\n  <link rel=\"preconnect\" href=\"https://avatars.githubusercontent.com\">\\n\\n\\n\\n  <link crossorigin=\"anonymous\" media=\"all\" integrity=\"sha512-E9wnWjoxQmh5A1jiWVYDPKOvA8VPf0iKQYoc+9ycMJvtAi9gOSlaUci+W2smxFIlWkV8hkX+O27S8NIB59iIDw==\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/light-13dc275a3a314268790358e25956033c.css\" /><link crossorigin=\"anonymous\" media=\"all\" integrity=\"sha512-nYSv3KrFhMlGUpjkFQBLMEN6HvHhijcoubQLjV3DWlcABEi2yDYf6KGUjRubJ5R+dJnKXR7jA4wu5Dg200SApA==\" rel=\"s'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_contents = response.text\n",
    "page_contents[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7486975e",
   "metadata": {},
   "source": [
    "- Here we see that the webpage is basically all HTML and the different things we want to extract from this webpage will be available under similar tags making it extractable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016026c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b26b128",
   "metadata": {},
   "source": [
    "## Use Beautiful Soup to parse and extract information\n",
    "\n",
    "- Parse and explore the structure of downloaded web pages using Beautiful soup.\n",
    "- Use the right properties and methods to extract the required information.\n",
    "- Create functions to extract from the page into lists and dictionaries.\n",
    "- (Optional) Use a REST API to acquire additional information if required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4452311",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ac6d3",
   "metadata": {},
   "source": [
    "- We install beautiful soup which will help us parse and extract the information form the webpage we saved in page_contents \n",
    "- --quiet mutes the output which is shown when the package is sucessfully installed\n",
    "- We use the Beautiful Soup Documentations to learn further how to import and use it for parsing and extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea76efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d184b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = BeautifulSoup(page_contents,'html.parser') # doc is the parsed HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8acbbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tags = doc.findAll('p')\n",
    "len(p_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bc7320",
   "metadata": {},
   "source": [
    "- When we see the number of p tags in the parsed HTML document we see that a total of 67 p tags are found but in the webpage the total number of topics are far lesser than the total number of p_tags hence we need to be more specific in extracting the topics. This can be done by examining the tags we have extracted right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da60f19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"f4 color-fg-muted col-md-6 mx-auto\">Browse popular topics on GitHub.</p>,\n",
       " <p class=\"f3 lh-condensed text-center Link--primary mb-0 mt-1\">\n",
       "         Maven\n",
       "       </p>,\n",
       " <p class=\"f5 color-fg-muted text-center mb-0 mt-1\">Maven is a build automation tool used primarily for Java projects.</p>,\n",
       " <p class=\"f3 lh-condensed text-center Link--primary mb-0 mt-1\">\n",
       "         PHP\n",
       "       </p>,\n",
       " <p class=\"f5 color-fg-muted text-center mb-0 mt-1\">PHP is a popular general-purpose scripting language that works particularly well for server-side web development.</p>,\n",
       " <p class=\"f3 lh-condensed text-center Link--primary mb-0 mt-1\">\n",
       "         jQuery\n",
       "       </p>,\n",
       " <p class=\"f5 color-fg-muted text-center mb-0 mt-1\">jQuery is a lightweight library that simplifies programming with JavaScript.</p>,\n",
       " <p class=\"f3 lh-condensed mb-0 mt-1 Link--primary\">3D</p>,\n",
       " <p class=\"f5 color-fg-muted mb-0 mt-1\">\n",
       "           3D modeling is the process of virtually developing the surface and structure of a 3D object.\n",
       "         </p>,\n",
       " <p class=\"f3 lh-condensed mb-0 mt-1 Link--primary\">Ajax</p>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tags[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a514a8e",
   "metadata": {},
   "source": [
    "- So we see that we were able to get some of the topics but we got unecessary things too. So we use the exact class used for the topics for extracting the exact topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff2b43a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"f3 lh-condensed mb-0 mt-1 Link--primary\">3D</p>,\n",
       " <p class=\"f3 lh-condensed mb-0 mt-1 Link--primary\">Ajax</p>,\n",
       " <p class=\"f3 lh-condensed mb-0 mt-1 Link--primary\">Algorithm</p>,\n",
       " <p class=\"f3 lh-condensed mb-0 mt-1 Link--primary\">Amp</p>,\n",
       " <p class=\"f3 lh-condensed mb-0 mt-1 Link--primary\">Android</p>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "\n",
    "topic_title_tags = doc.findAll('p', class_= selection_class)\n",
    "topic_title_tags[:5]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5831603e",
   "metadata": {},
   "source": [
    "- We see that we were able to extract the exactly the topic titles\n",
    "- Now we will try to extract the topic titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "47a391b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"f5 color-fg-muted mb-0 mt-1\">\n",
       "           3D modeling is the process of virtually developing the surface and structure of a 3D object.\n",
       "         </p>,\n",
       " <p class=\"f5 color-fg-muted mb-0 mt-1\">\n",
       "           Ajax is a technique for creating interactive web applications.\n",
       "         </p>,\n",
       " <p class=\"f5 color-fg-muted mb-0 mt-1\">\n",
       "           Algorithms are self-contained sequences that carry out a variety of tasks.\n",
       "         </p>,\n",
       " <p class=\"f5 color-fg-muted mb-0 mt-1\">\n",
       "           Amp is a non-blocking concurrency framework for PHP.\n",
       "         </p>,\n",
       " <p class=\"f5 color-fg-muted mb-0 mt-1\">\n",
       "           Android is an operating system built by Google designed for mobile devices.\n",
       "         </p>]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_class='f5 color-fg-muted mb-0 mt-1'\n",
    "topic_desc_tags = doc.findAll('p', class_=desc_class)\n",
    "topic_desc_tags[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba3e54",
   "metadata": {},
   "source": [
    "- Now that we are able to extract the tags we need to extract the exact text we need from the tags i.e. '3D' from ```<p class=\"f3 lh-condensed mb-0 mt-1 Link--primary\">3D</p>``` we can do this by using .text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "22b663bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3D'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_title_tags[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de6c22a",
   "metadata": {},
   "source": [
    "- We now create a list to store the texts from the title tags to titles only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f944a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3D', 'Ajax', 'Algorithm', 'Amp', 'Android']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_titles = []\n",
    "for tag in topic_title_tags:\n",
    "    topic_titles.append(tag.text)\n",
    "topic_titles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15ca7e6",
   "metadata": {},
   "source": [
    "- Similarly we make one for topic descriptions\n",
    "- We use strip because there are empty spaces in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9d6b1d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3D modeling is the process of virtually developing the surface and structure of a 3D object.',\n",
       " 'Ajax is a technique for creating interactive web applications.',\n",
       " 'Algorithms are self-contained sequences that carry out a variety of tasks.',\n",
       " 'Amp is a non-blocking concurrency framework for PHP.',\n",
       " 'Android is an operating system built by Google designed for mobile devices.']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_desc = []\n",
    "for tag in topic_desc_tags:\n",
    "    topic_desc.append(tag.text.strip())\n",
    "topic_desc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8669e40",
   "metadata": {},
   "source": [
    "- Next we need is the topic urls for that we learn from the documentation of beautiful soup that .parent gives us the parent of the tag used before (example below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "68fdbcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"no-underline flex-1 d-flex flex-column\" href=\"/topics/3d\">\n",
       "<p class=\"f3 lh-condensed mb-0 mt-1 Link--primary\">3D</p>\n",
       "<p class=\"f5 color-fg-muted mb-0 mt-1\">\n",
       "          3D modeling is the process of virtually developing the surface and structure of a 3D object.\n",
       "        </p>\n",
       "</a>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_title_tags[0].parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092dc52",
   "metadata": {},
   "source": [
    "- Using that we selectively extract the ['href'] from those tags and append them with \"https://github.com\" which will make them the complete url for that topic respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dec08d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/topics/3d',\n",
       " 'https://github.com/topics/ajax',\n",
       " 'https://github.com/topics/algorithm',\n",
       " 'https://github.com/topics/amphp',\n",
       " 'https://github.com/topics/android']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_urls = []\n",
    "base_url=\"https://github.com\"\n",
    "for tag in topic_title_tags:\n",
    "    topic_urls.append(base_url+tag.parent['href'])\n",
    "topic_urls[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51185b7",
   "metadata": {},
   "source": [
    "- Next thing we are going to learn making CSV files using pandas library\n",
    "- it can be installed using ```!pip install pandas``` but since we are using anaconda we don't need to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a386ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9525e3f",
   "metadata": {},
   "source": [
    "- Then from the pandas documentation we learn how to make a dataframe from a list, hence arranging the the data we extracted above in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7a148caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_dict = {'title': topic_titles, 'description': topic_desc, 'url':topic_urls}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441293ce",
   "metadata": {},
   "source": [
    "- We make a dictionary of the lists from which we'll extract the data and then using pandas we make a DataFrame (basically a spreadsheet) and arrange it in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0e2ed127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D</td>\n",
       "      <td>3D modeling is the process of virtually develo...</td>\n",
       "      <td>https://github.com/topics/3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax is a technique for creating interactive w...</td>\n",
       "      <td>https://github.com/topics/ajax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algorithm</td>\n",
       "      <td>Algorithms are self-contained sequences that c...</td>\n",
       "      <td>https://github.com/topics/algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amp</td>\n",
       "      <td>Amp is a non-blocking concurrency framework fo...</td>\n",
       "      <td>https://github.com/topics/amphp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Android</td>\n",
       "      <td>Android is an operating system built by Google...</td>\n",
       "      <td>https://github.com/topics/android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title                                        description  \\\n",
       "0         3D  3D modeling is the process of virtually develo...   \n",
       "1       Ajax  Ajax is a technique for creating interactive w...   \n",
       "2  Algorithm  Algorithms are self-contained sequences that c...   \n",
       "3        Amp  Amp is a non-blocking concurrency framework fo...   \n",
       "4    Android  Android is an operating system built by Google...   \n",
       "\n",
       "                                   url  \n",
       "0         https://github.com/topics/3d  \n",
       "1       https://github.com/topics/ajax  \n",
       "2  https://github.com/topics/algorithm  \n",
       "3      https://github.com/topics/amphp  \n",
       "4    https://github.com/topics/android  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df = pd.DataFrame(topics_dict)\n",
    "topics_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1880e58b",
   "metadata": {},
   "source": [
    "## Getting information out of a topic page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d5dd9a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://github.com/topics/3d'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_page_url= topic_urls[0]\n",
    "topic_page_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "46ecbcc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reponse = requests.get(topic_page_url)\n",
    "reponse.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "538f17e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_doc = BeautifulSoup(reponse.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "edef5c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_selection_class = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "repo_tags = topic_doc.findAll('h3', class_= h3_selection_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5492295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_selection_class = 'Counter js-social-count'\n",
    "star_tags = topic_doc.findAll('span',class_= star_selection_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "98f679d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_star_count(star_str):\n",
    "    star_str = star_str.strip()\n",
    "    if star_str[-1] == 'k' :\n",
    "        return int(float(star_str[:-1])*1000)\n",
    "    return int(star_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "01a48f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_repos_dict={'username': [],'repo_name':[], 'stars':[], 'repo_url': []}\n",
    "for i in range(len(repo_tags)):\n",
    "    repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
    "    topic_repos_dict['username'].append(repo_info[0])\n",
    "    topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "    topic_repos_dict['stars'].append(repo_info[2])\n",
    "    topic_repos_dict['repo_url'].append(repo_info[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0478fb",
   "metadata": {},
   "source": [
    "## Create CSV file(s) with the extracted information\n",
    "\n",
    "- Create functions for the end-to-end process of downloading, parsing, and saving CSVs.\n",
    "- Execute the function with different inputs to create a dataset of CSV files.\n",
    "- Verify the information in the CSV files by reading them back using Pandas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae3e468",
   "metadata": {},
   "source": [
    "# Final Code\n",
    "\n",
    "- Here we make different functions for all the things we have learnt above and call one function which will call every other function and in the end make different .csv files for everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbb4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def get_topic_page(topic_url):\n",
    "    \n",
    "    #Download the page\n",
    "\n",
    "    response = requests.get(topic_url)\n",
    "    \n",
    "    #Check successful response\n",
    "    \n",
    "    if response.status_code != 200 :\n",
    "        raise Exception('Failed to load page{}'.format(topic_url))\n",
    "    \n",
    "    #Parse using BeautifulSoup\n",
    "    \n",
    "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    return topic_doc\n",
    "    \n",
    "    def get_repo_info(h3_tag, star_tag):\n",
    "        \n",
    "        #return all the required information about the repository\n",
    "        \n",
    "        a_tags = h3_tag.findAll('a')\n",
    "        username = a_tags[0].text.strip()\n",
    "        repo_name= a_tags[1].text.strip()\n",
    "        repo_url = base_url + a_tags[1]['href']\n",
    "        stars = parse_star_count(star_tag.text.strip())\n",
    "        return username, repo_name, stars, repo_url\n",
    "\n",
    "def get_topic_repos(topic_doc):\n",
    "    \n",
    "    #Get h3 tags containing repo title, repo URL, and username\n",
    "    \n",
    "    h3_selection_class = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "    repo_tags = topic_doc.findAll('h3', class_= h3_selection_class)\n",
    "    \n",
    "    #Get star tags\n",
    "    \n",
    "    star_selection_class = 'Counter js-social-count'\n",
    "    star_tags = topic_doc.findAll('span',class_= star_selection_class)\n",
    "    \n",
    "    #get repo info\n",
    "    \n",
    "    topic_repos_dict={'username': [],'repo_name':[], 'stars':[], 'repo_url': []}\n",
    "    for i in range(len(repo_tags)):\n",
    "        repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
    "        topic_repos_dict['username'].append(repo_info[0])\n",
    "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repos_dict['stars'].append(repo_info[2])\n",
    "        topic_repos_dict['repo_url'].append(repo_info[3])\n",
    "        \n",
    "    return pd.DataFrame(topic_repos_dict)\n",
    "\n",
    "def scrape_topic(topic_url,path):\n",
    "    if os.path.exists(path):\n",
    "        print(\"The file {} already exists. Skipping...\".format(path))\n",
    "        return\n",
    "    topic_df=get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(path ,index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1bd0c9",
   "metadata": {},
   "source": [
    "Writing different function to :\n",
    "1. Get the list of topics from the topic page\n",
    "2. Get the lidt of top repos from the individual topic page\n",
    "3. For each topic, create a CSV of the top repos for the topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b09ef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_titles(doc):\n",
    "    \n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topic_title_tags = doc.findAll('p', class_= selection_class)\n",
    "    \n",
    "    topic_titles = []\n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text)\n",
    "    return topic_titles\n",
    "\n",
    "def get_topic_descs(doc):\n",
    "    desc_class='f5 color-fg-muted mb-0 mt-1'\n",
    "    topic_desc_tags = doc.findAll('p', class_= desc_class)\n",
    "    \n",
    "    topic_desc = []\n",
    "    for tag in topic_desc_tags:\n",
    "        topic_desc.append(tag.text.strip()) \n",
    "    return topic_desc\n",
    "\n",
    "def get_topic_urls(doc):\n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topic_title_tags = doc.findAll('p', class_= selection_class)\n",
    "    \n",
    "    topic_urls = []\n",
    "    base_url=\"https://github.com\"\n",
    "    for tag in topic_title_tags:\n",
    "        topic_urls.append(base_url+tag.parent['href'])\n",
    "    return topic_urls\n",
    "\n",
    "def scrape_topics():\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    requests.get(topics_url)\n",
    "    if response.status_code != 200 :\n",
    "        raise Exception('Failed to load page{}'.format(topic_url))\n",
    "    topics_dict = {'title': get_topic_titles(doc),  'description': get_topic_descs(doc), 'url': get_topic_urls(doc)}\n",
    "    return pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "622b9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topic_repos():\n",
    "    print('Scraping list of topics')\n",
    "    topics_df= scrape_topics()\n",
    "    \n",
    "    os.makedirs('data',exist_ok=True)\n",
    "    for index, row in topics_df.iterrows():\n",
    "        print('Scraping top repositories for \"{}\"'.format(row['title']))\n",
    "        scrape_topic(row['url'],'data/{}'.format(row['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6fec9509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping list of topics\n",
      "Scraping top repositories for \"3D\"\n",
      "Scraping top repositories for \"Ajax\"\n",
      "Scraping top repositories for \"Algorithm\"\n",
      "Scraping top repositories for \"Amp\"\n",
      "Scraping top repositories for \"Android\"\n",
      "Scraping top repositories for \"Angular\"\n",
      "Scraping top repositories for \"Ansible\"\n",
      "Scraping top repositories for \"API\"\n",
      "Scraping top repositories for \"Arduino\"\n",
      "Scraping top repositories for \"ASP.NET\"\n",
      "Scraping top repositories for \"Atom\"\n",
      "Scraping top repositories for \"Awesome Lists\"\n",
      "Scraping top repositories for \"Amazon Web Services\"\n",
      "Scraping top repositories for \"Azure\"\n",
      "Scraping top repositories for \"Babel\"\n",
      "Scraping top repositories for \"Bash\"\n",
      "Scraping top repositories for \"Bitcoin\"\n",
      "Scraping top repositories for \"Bootstrap\"\n",
      "Scraping top repositories for \"Bot\"\n",
      "Scraping top repositories for \"C\"\n",
      "Scraping top repositories for \"Chrome\"\n",
      "Scraping top repositories for \"Chrome extension\"\n",
      "Scraping top repositories for \"Command line interface\"\n",
      "Scraping top repositories for \"Clojure\"\n",
      "Scraping top repositories for \"Code quality\"\n",
      "Scraping top repositories for \"Code review\"\n",
      "Scraping top repositories for \"Compiler\"\n",
      "Scraping top repositories for \"Continuous integration\"\n",
      "Scraping top repositories for \"COVID-19\"\n",
      "Scraping top repositories for \"C++\"\n"
     ]
    }
   ],
   "source": [
    "scrape_topic_repos()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
